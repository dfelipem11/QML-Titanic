{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85ad8a4e",
   "metadata": {},
   "source": [
    "# Parcial final: Daniel Meneses Rojas C.C. 1036671105\n",
    "\n",
    "### Modelo QML Titanic Original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716bb709",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df668049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math                                                 # Libreria para calculos matemáticos\n",
    "import pandas as pd                                         # Libreria para manipular de datos\n",
    "import pennylane as qml                                     # Libreria necesaria para computación cuántica\n",
    "from pennylane import numpy as np                           # Versión diferenciable de numpy\n",
    "from pennylane.optimize import AdamOptimizer                # Optimizador Adam para el entrenamiento \n",
    "\n",
    "# Libreria para dividir los datos de entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split        \n",
    "# Métricas de evaluación\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7174e1",
   "metadata": {},
   "source": [
    "## **I.** Preprocesamiento de los datos de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb676de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')                      # Carga el dataset desde un archivo CSV\n",
    "df_train['Pclass'] = df_train['Pclass'].astype(str)      # Convierte la columna 'Pclass' a tipo string\n",
    "\n",
    "# Codificación one-hot para las variables categóricas\n",
    "df_train = pd.concat([df_train, pd.get_dummies(df_train[['Pclass', 'Sex', 'Embarked']])], axis=1)\n",
    "\n",
    "# Llena los valores faltantes de 'Age' con la mediana\n",
    "df_train['Age'] = df_train['Age'].fillna(df_train['Age'].median())\n",
    "\n",
    "# Crea una nueva columna para identificar si es niño (<12 años)\n",
    "df_train['is_child'] = df_train['Age'].map(lambda x: 1 if x < 12 else 0)\n",
    "\n",
    "# Selecciona las variables para el modelo\n",
    "cols_model = ['is_child', 'Pclass_1', 'Pclass_2', 'Sex_female']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dcf4b7",
   "metadata": {},
   "source": [
    "## **II.** División de datos de entrada y datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30114ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de datos de entrenamiento y datos de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train[cols_model], df_train['Survived'], test_size=0.10, random_state=42, stratify=df_train['Survived'])  # División estratificada\n",
    "\n",
    "# Conversión a arrays de Pennylane (diferenciables)\n",
    "X_train = np.array(X_train.values, requires_grad=False)\n",
    "\n",
    "# Conversión de etiquetas {0,1} a {-1,1} (necesario para el clasificador cuántico)\n",
    "Y_train = np.array(y_train.values * 2 - np.ones(len(y_train)), requires_grad=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99686ab7",
   "metadata": {},
   "source": [
    "## **III.** Etapa del Feature Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15271527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del dispositivo cuántico con 4 qubits\n",
    "num_qubits = 4\n",
    "num_layers = 2\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits)         # Simulador de qubits\n",
    "\n",
    "# Etapa del Feature Map\n",
    "def statepreparation(x):\n",
    "    qml.BasisEmbedding(x, wires=range(0, num_qubits))       # Codifica los datos clásicos como estados base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e731961",
   "metadata": {},
   "source": [
    "## **IV.** Etapa del Ansatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a6ff57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(W):\n",
    "    # Aplica rotaciones arbitrarias en cada qubit\n",
    "    qml.Rot(W[0, 0], W[0, 1], W[0, 2], wires=0)\n",
    "    qml.Rot(W[1, 0], W[1, 1], W[1, 2], wires=1)\n",
    "    qml.Rot(W[2, 0], W[2, 1], W[2, 2], wires=2)\n",
    "    qml.Rot(W[3, 0], W[3, 1], W[3, 2], wires=3)\n",
    "\n",
    "    # Aplica compuertas CNOT para entrelazar los qubits\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.CNOT(wires=[1, 2])\n",
    "    qml.CNOT(wires=[2, 3])\n",
    "    qml.CNOT(wires=[3, 0])\n",
    "\n",
    "# Definición del circuito cuántico completo\n",
    "@qml.qnode(dev, interface=\"autograd\")\n",
    "def circuit(weights, x):\n",
    "    statepreparation(x)                         # Aplica el feature map (codificación)\n",
    "    for W in weights:\n",
    "        layer(W)                                # Aplica cada capa del ansatz\n",
    "    return qml.expval(qml.PauliZ(0))            # Retorna la expectativa de PauliZ en el qubit 0\n",
    "\n",
    "# Función del clasificador variacional\n",
    "def variational_classifier(weights, bias, x):\n",
    "    return circuit(weights, x) + bias           # Predicción = salida del circuito + sesgo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620ffd89",
   "metadata": {},
   "source": [
    "## **V.** Etapa de funcion de Pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4ded8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss += (l - p) ** 2           # Error cuadrático por muestra\n",
    "    return loss / len(labels)         # Promedio del error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a173e38",
   "metadata": {},
   "source": [
    "## **VI.** Etapa de evaluación de la Función de Costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b48549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights, bias, X, Y):\n",
    "    predictions = [variational_classifier(weights, bias, x) for x in X]     # Clasifica todos los datos\n",
    "    return square_loss(Y, predictions)                                      # Calcula el costo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8122bcde",
   "metadata": {},
   "source": [
    "## **VII.** Etapa de Análisis de Precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "305b52b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, predictions):\n",
    "    correct = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:               # Cuenta como correcta si predicción y etiqueta coinciden\n",
    "            correct += 1\n",
    "    return correct / len(labels)            # Porcentaje de aciertos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1148fe",
   "metadata": {},
   "source": [
    "## **VIII.** Pesos iniciales definidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06cc5425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semilla para reproducibilidad\n",
    "np.random.seed(0)               \n",
    "\n",
    "# Inicialización aleatoria de pesos\n",
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)  \n",
    "\n",
    "# Sesgo inicial\n",
    "bias_init = np.array(0.0, requires_grad=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7be64e",
   "metadata": {},
   "source": [
    "## **IX.** Pesos finales entrenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebee0d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:     1 | Cost: 2.3009047 | Accuracy: 0.3657928\n",
      "Iter:     2 | Cost: 2.0028599 | Accuracy: 0.3657928\n",
      "Iter:     3 | Cost: 1.6788013 | Accuracy: 0.3657928\n",
      "Iter:     4 | Cost: 1.4103476 | Accuracy: 0.3570537\n",
      "Iter:     5 | Cost: 1.2370707 | Accuracy: 0.6167291\n",
      "Iter:     6 | Cost: 1.1592230 | Accuracy: 0.6167291\n",
      "Iter:     7 | Cost: 1.1155736 | Accuracy: 0.6167291\n",
      "Iter:     8 | Cost: 1.0833781 | Accuracy: 0.6167291\n",
      "Iter:     9 | Cost: 1.0364816 | Accuracy: 0.6167291\n",
      "Iter:    10 | Cost: 0.9838059 | Accuracy: 0.6167291\n",
      "Iter:    11 | Cost: 0.9350933 | Accuracy: 0.6167291\n",
      "Iter:    12 | Cost: 0.9040926 | Accuracy: 0.6779026\n",
      "Iter:    13 | Cost: 0.8772236 | Accuracy: 0.6766542\n",
      "Iter:    14 | Cost: 0.8435462 | Accuracy: 0.7802747\n",
      "Iter:    15 | Cost: 0.8127882 | Accuracy: 0.7802747\n",
      "Iter:    16 | Cost: 0.7705518 | Accuracy: 0.7802747\n",
      "Iter:    17 | Cost: 0.7427210 | Accuracy: 0.7802747\n",
      "Iter:    18 | Cost: 0.7298644 | Accuracy: 0.7802747\n",
      "Iter:    19 | Cost: 0.7286801 | Accuracy: 0.7802747\n",
      "Iter:    20 | Cost: 0.7333229 | Accuracy: 0.7840200\n",
      "Iter:    21 | Cost: 0.7234688 | Accuracy: 0.7840200\n",
      "Iter:    22 | Cost: 0.7143377 | Accuracy: 0.7840200\n",
      "Iter:    23 | Cost: 0.7024496 | Accuracy: 0.7840200\n",
      "Iter:    24 | Cost: 0.6892683 | Accuracy: 0.7840200\n",
      "Iter:    25 | Cost: 0.6772319 | Accuracy: 0.7840200\n",
      "Iter:    26 | Cost: 0.6731195 | Accuracy: 0.7840200\n",
      "Iter:    27 | Cost: 0.6728468 | Accuracy: 0.7840200\n",
      "Iter:    28 | Cost: 0.6735666 | Accuracy: 0.7840200\n",
      "Iter:    29 | Cost: 0.6734933 | Accuracy: 0.7840200\n",
      "Iter:    30 | Cost: 0.6739623 | Accuracy: 0.7840200\n"
     ]
    }
   ],
   "source": [
    "opt = AdamOptimizer(0.125)                          # Optimizador Adam con tasa de aprendizaje 0.125\n",
    "num_it = 30                                         # Número de iteraciones de entrenamiento\n",
    "batch_size = math.floor(len(X_train) / num_it)      # Tamaño de minibatch\n",
    "\n",
    "weights = weights_init                                 # Copia de los pesos\n",
    "bias = bias_init\n",
    "\n",
    "# Ciclo de entrenamiento\n",
    "for it in range(num_it):\n",
    "    # Selección aleatoria de minibatch\n",
    "    batch_index = np.random.randint(0, len(X_train), (batch_size,))\n",
    "    X_batch = X_train[batch_index]\n",
    "    Y_batch = Y_train[batch_index]\n",
    "\n",
    "    # Paso de optimización\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, X_batch, Y_batch)\n",
    "\n",
    "    # Cálculo de precisión en todo el conjunto de entrenamiento\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X_train]\n",
    "    acc = accuracy(Y_train, predictions)\n",
    "\n",
    "    # Imprime información del progreso\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f}\".format(\n",
    "            it + 1, cost(weights, bias, X_train, Y_train), acc\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a6112c",
   "metadata": {},
   "source": [
    "## **X.** Evaluación de desempeño del clasificador cuantico final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4769855b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7888888888888889\n",
      "Precision Score: 0.7666666666666667\n",
      "Recall Score: 0.6571428571428571\n",
      "F1 Score (macro): 0.7712374581939799\n"
     ]
    }
   ],
   "source": [
    "# Evaluación de desempeño del clasificador\n",
    "X_test = np.array(X_test.values, requires_grad=False)\n",
    "Y_test = np.array(y_test.values * 2 - np.ones(len(y_test)), requires_grad=False)\n",
    "\n",
    "# Realiza las predicciones con el modelo de entrenado\n",
    "predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X_test]\n",
    "\n",
    "# Se evalua el desempeño con las metricas de exactitud, precisión y recall\n",
    "print(\"Accuracy Score:\", accuracy_score(Y_test, predictions))\n",
    "print(\"Precision Score:\", precision_score(Y_test, predictions))\n",
    "print(\"Recall Score:\", recall_score(Y_test, predictions))\n",
    "print(\"F1 Score (macro):\", f1_score(Y_test, predictions, average='macro'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
